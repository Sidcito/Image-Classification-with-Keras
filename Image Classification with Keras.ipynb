{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CIFAR_10 is a set of 60,000 images of 32X32 pixels with dept RBG\n",
    "IMG_CHANNELS= 3\n",
    "IMG_ROWS= 32\n",
    "IMG_COLS= 32\n",
    "\n",
    "#Constants\n",
    "BATCH_SIZE= 128\n",
    "NB_EPOCHS= 20\n",
    "NB_CLASSES= 10\n",
    "VERBOSE= 1\n",
    "VALIDATION_SPLIT= 0.2\n",
    "OPTIM= RMSprop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the datasets\n",
    "(X_train, y_train), (X_test, y_test)= cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot encoding, converting to categorical\n",
    "Y_train= np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test= np_utils.to_categorical(y_test, NB_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#and normalizing the images\n",
    "X_train= X_train.astype('float32')\n",
    "X_test= X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Our net will learn 32 convolutional filters, each of which with a 3 x 3 size. \n",
    "#The output dimension is the same one of the input shape, so it will be 32 x 32 \n",
    "#and activation is ReLU, which is a simple way of introducing non-linearity. \n",
    "#After that we have a max-pooling operation with pool size 2 x 2 and a dropout at 25%:\n",
    "#N=32 Padding=1 F=3\n",
    "\n",
    "model= Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), padding='same', input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               4194816   \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 4,200,842\n",
      "Trainable params: 4,200,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#The next stage in the deep pipeline is a dense network with 512 units and ReLU activation followed\n",
    "#by a dropout at 50% and by a softmax layer with 10 classes as output, one for each category\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "40000/40000 [==============================] - 87s 2ms/step - loss: 1.8178 - acc: 0.3723 - val_loss: 1.4746 - val_acc: 0.4855\n",
      "Epoch 2/20\n",
      "40000/40000 [==============================] - 88s 2ms/step - loss: 1.4113 - acc: 0.4975 - val_loss: 1.3048 - val_acc: 0.5420\n",
      "Epoch 3/20\n",
      "40000/40000 [==============================] - 87s 2ms/step - loss: 1.2863 - acc: 0.5454 - val_loss: 1.2615 - val_acc: 0.5526\n",
      "Epoch 4/20\n",
      "40000/40000 [==============================] - 86s 2ms/step - loss: 1.1935 - acc: 0.5786 - val_loss: 1.2263 - val_acc: 0.5691\n",
      "Epoch 5/20\n",
      "40000/40000 [==============================] - 84s 2ms/step - loss: 1.1301 - acc: 0.6038 - val_loss: 1.0987 - val_acc: 0.6158\n",
      "Epoch 6/20\n",
      "40000/40000 [==============================] - 86s 2ms/step - loss: 1.0706 - acc: 0.6223 - val_loss: 1.0827 - val_acc: 0.6213\n",
      "Epoch 7/20\n",
      "40000/40000 [==============================] - 88s 2ms/step - loss: 1.0240 - acc: 0.6395 - val_loss: 1.1862 - val_acc: 0.5902\n",
      "Epoch 8/20\n",
      "40000/40000 [==============================] - 87s 2ms/step - loss: 0.9757 - acc: 0.6577 - val_loss: 1.0619 - val_acc: 0.6310\n",
      "Epoch 9/20\n",
      "40000/40000 [==============================] - 84s 2ms/step - loss: 0.9351 - acc: 0.6753 - val_loss: 1.0233 - val_acc: 0.6486\n",
      "Epoch 10/20\n",
      "40000/40000 [==============================] - 85s 2ms/step - loss: 0.9023 - acc: 0.6840 - val_loss: 1.0356 - val_acc: 0.6451\n",
      "Epoch 11/20\n",
      "40000/40000 [==============================] - 85s 2ms/step - loss: 0.8629 - acc: 0.7011 - val_loss: 1.0341 - val_acc: 0.6510\n",
      "Epoch 12/20\n",
      "40000/40000 [==============================] - 85s 2ms/step - loss: 0.8304 - acc: 0.7105 - val_loss: 1.0404 - val_acc: 0.6470\n",
      "Epoch 13/20\n",
      "40000/40000 [==============================] - 90s 2ms/step - loss: 0.8022 - acc: 0.7207 - val_loss: 1.0185 - val_acc: 0.6709\n",
      "Epoch 14/20\n",
      "40000/40000 [==============================] - 90s 2ms/step - loss: 0.7802 - acc: 0.7283 - val_loss: 1.0900 - val_acc: 0.6451\n",
      "Epoch 15/20\n",
      "40000/40000 [==============================] - 90s 2ms/step - loss: 0.7422 - acc: 0.7409 - val_loss: 1.0966 - val_acc: 0.6562\n",
      "Epoch 16/20\n",
      "40000/40000 [==============================] - 87s 2ms/step - loss: 0.7283 - acc: 0.7478 - val_loss: 1.0226 - val_acc: 0.6628\n",
      "Epoch 17/20\n",
      "40000/40000 [==============================] - 813s 20ms/step - loss: 0.6961 - acc: 0.7585 - val_loss: 1.0578 - val_acc: 0.6722\n",
      "Epoch 18/20\n",
      "40000/40000 [==============================] - 4369s 109ms/step - loss: 0.6765 - acc: 0.7642 - val_loss: 1.0772 - val_acc: 0.6708\n",
      "Epoch 19/20\n",
      "40000/40000 [==============================] - 84s 2ms/step - loss: 0.6578 - acc: 0.7705 - val_loss: 1.0311 - val_acc: 0.6723\n",
      "Epoch 20/20\n",
      "40000/40000 [==============================] - 124s 3ms/step - loss: 0.6346 - acc: 0.7816 - val_loss: 0.9989 - val_acc: 0.6849\n",
      "10000/10000 [==============================] - 7s 697us/step\n"
     ]
    }
   ],
   "source": [
    "#Training the model, creating a validation set\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIM, metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size= BATCH_SIZE, epochs= NB_EPOCHS, validation_split= VALIDATION_SPLIT, verbose= VERBOSE)\n",
    "score= model.evaluate(X_test, Y_test, batch_size= BATCH_SIZE, verbose= VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.995791262436\n",
      "Test accuracy 0.6738\n"
     ]
    }
   ],
   "source": [
    "print(\"Test score:\", score[0])\n",
    "print(\"Test accuracy\", score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
